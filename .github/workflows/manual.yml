name: Training
on:
  workflow_dispatch:
    inputs:
      k8s_deploy:
        type: choice
        description: needs to k8s_deploy?
        options:
          - True
          - False
      update_last_model:
        type: choice
        description: update last model?
        options:
          - True
          - False

jobs:
#  init_database:
#    runs-on: ubuntu-latest
#    steps:
#      - name: checkout repo content
#        uses: actions/checkout@v3
#      - name: setup python
#        with:
#          python-version: '3.9'
#          cache: 'pip'
#        uses: actions/setup-python@v4
#      - name: install script requirements
#        run: pip install -r requirements.txt
#      - name: init database
#        env:
#          DB_USERNAME: admangarakov
#          DB_PASSWORD: ${{secrets.DB_PASS}}
#        run: python src/database_init.py

  load_dataset:
#    needs: init_database
    runs-on: ubuntu-latest
    steps:
      - name: checkout repo content
        uses: actions/checkout@v3
      - name: install kaggle API
        run: pip install kaggle
      - name: download dataset
        env:
          KAGGLE_USERNAME: niruksorp11
          KAGGLE_KEY: ${{secrets.KAGGLE_PASS}}
        run: kaggle datasets download advaypatil/youtube-statistics
      - name: unpack dataset archive
        run: unzip youtube-statistics.zip
      - name: install script requirements
        run: pip install -r requirements.txt
      - name: fill database
        env:
          DB_USERNAME: admangarakov
          DB_PASSWORD: ${{secrets.DB_PASS}}
        run: python src/dataset_loading.py "comments.csv"

  vectorize_dataset:
    needs: load_dataset
    runs-on: ubuntu-latest
    steps:
      - name: checkout repo content
        uses: actions/checkout@v3
      - name: install script requirements
        run: pip install -r requirements.txt
      - name: vectorize dataset
        env:
          DB_PASSWORD: ${{secrets.DB_PASS}}
        run: python src/data_preprocessing.py 1

  train:
    if: github.event.inputs.update_last_model == 'False'
    needs: vectorize_dataset
    runs-on: ubuntu-latest
    steps:
      - name: checkout repo content
        uses: actions/checkout@v3
      - name: install script requirements
        run: pip install -r requirements.txt
      - name: train
        env:
          DB_PASSWORD: ${{secrets.DB_PASS}}
        run: python src/train.py 100

  train_perceptron:
    if: github.event.inputs.update_last_model == 'False'
    needs: vectorize_dataset
    runs-on: ubuntu-latest
    steps:
      - name: checkout repo content
        uses: actions/checkout@v3
      - name: install script requirements
        run: pip install -r requirements.txt
      - name: train_perceptron
        env:
          DB_PASSWORD: ${{secrets.DB_PASS}}
        run: python src/train_perceptron.py 100

  retrain:
    if: github.event.inputs.update_last_model == 'True'
    needs: vectorize_dataset
    runs-on: ubuntu-latest
    steps:
      - name: checkout repo content
        uses: actions/checkout@v3
      - name: install script requirements
        run: pip install -r requirements.txt
      - name: retraining
        env:
          DB_PASSWORD: ${{secrets.DB_PASS}}
        run: python src/retraining.py 100 log_reg

  retrain_perceptron:
    if: github.event.inputs.update_last_model == 'True'
    needs: vectorize_dataset
    runs-on: ubuntu-latest
    steps:
      - name: checkout repo content
        uses: actions/checkout@v3
      - name: install script requirements
        run: pip install -r requirements.txt
      - name: retrain_perceptron
        env:
          DB_PASSWORD: ${{secrets.DB_PASS}}
        run: python src/retraining_perceptron.py 10

  quantization:
    if: ${{ always() }}
    needs: [ retrain, train ]
    runs-on: ubuntu-latest
    steps:
      - name: checkout repo content
        uses: actions/checkout@v3
      - name: install script requirements
        run: pip install -r requirements.txt
      - name: quantization
        env:
          DB_PASSWORD: ${{secrets.DB_PASS}}
        run: python src/quantization.py

  quantization_perceptron:
    if: ${{ always() }}
    needs: [ retrain_perceptron, train_perceptron ]
    runs-on: ubuntu-latest
    steps:
      - name: checkout repo content
        uses: actions/checkout@v3
      - name: install script requirements
        run: pip install -r requirements.txt
      - name: quantization_perceptron
        env:
          DB_PASSWORD: ${{secrets.DB_PASS}}
        run: python src/quantization_perceptron.py

  model_deploy:
    if: ${{ always() }}
    needs: [ quantization, quantization_perceptron ]
    runs-on: self-hosted
    steps:
      - name: checkout repo content
        uses: actions/checkout@v3
      - name: deploy model
        working-directory: ./src
        env:
          DB_USERNAME: github
          DB_PASSWORD: ${{secrets.DBPASSWORD}}
        run: python3 update_server.py

  docker_build:
    if: github.event.inputs.k8s_deploy == 'True'
    needs: [retrain, retrain_perceptron, train, train_perceptron]
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v3
      - name: install script requirements
        run: pip install -r requirements.txt
      - name: prepare for deploy
        env:
          DB_PASSWORD: ${{secrets.DB_PASS}}
        run: python src/prepare_deploy.py
      - name: Log in to Docker Hub
        env:
          DOCKER_USERNAME: ${{ secrets.DOCKER_USERNAME }}
          DOCKER_PASSWORD: ${{ secrets.DOCKER_PASSWORD }}
        run: docker login -u $DOCKER_USERNAME -p $DOCKER_PASSWORD
      - name: Build Docker image
        run: docker build . --file Dockerfile --tag niruksorp/ifmo-comment-emmotionaly
      - name: Push into Docker Hub
        run: docker push niruksorp/ifmo-comment-emmotionaly

  deploy_k8s:
    if: github.event.inputs.k8s_deploy == 'True'
    needs: [retrain, retrain_perceptron, train, train_perceptron]
    runs-on: self-hosted
    steps:
      - uses: actions/checkout@master
      - name: deploy
        run: |
          ls
          kubectl apply -f manifest.yaml
          
